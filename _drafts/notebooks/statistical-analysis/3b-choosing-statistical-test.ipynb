{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38032bit64a64ed7a47843b8be3706a54e9a0958",
   "display_name": "Python 3.8.0 32-bit",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# STATISTICAL TESTS\n",
    "## Choosing a Statistical Test\n",
    "Choosing a [statistical test](http://www.biostathandbook.com/) depends on:\n",
    "+ what hypothesis is tested.\n",
    "+ the type of the variable of interest & its probability distribution.\n",
    "\n",
    "In some simple cases, we do not have to explicitely model relationships and can use specific statistical tests instead; The most common example is the t-test to compare two samples. As we'll see in the next article, these statistical tests are particular cases of more general linear models. For example, t-tests are a linear model where X = \"sample the observation belongs to\". We try to assess if there is a relationship between X and Y, or if the response depends on the sample.\n",
    "\n",
    "More generally, choosing a [statistical test](http://www.biostathandbook.com/) depends on what we want to measure:\n",
    "\n",
    "<br></br>\n",
    "![png](../../img/stat_tests/stat_tests_overview.png)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "___\n",
    "\n",
    "# DIFFERENCE BETWEEN SAMPLES\n",
    "## Overview\n",
    "\n",
    "Comparing samples aims to determine if some characteristics of the population have an impact on the variable of interest. More specifically, we check if different values of some **categorical variable(s)** lead to **different probability distributions** for the variable of interest.\n",
    "\n",
    "<br></br>\n",
    "![png](../../img/stat_tests/stat_tests_diff_between_samples.png)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "___\n",
    "\n",
    "# CORRELATION BETWEEN VARIABLES\n",
    "## Overview\n",
    "\n",
    "Correlation is the measure of dependance between **two continuous or ordinal variables**; It typically indicates their linear relationship, but more broadly measures how in sync they vary. This is expressed by their **covariance**. \n",
    "\n",
    "A more common measure is the **[Pearson product-moment correlation coefficient](https://en.wikipedia.org/wiki/Correlation_and_dependence#Pearson's_product-moment_coefficient)**, built on top of the covariance. It's akin to the standard variation vs the variance for bivariate data and represents how far the relationship is from the line of best fit.\n",
    "\n",
    "The correlation coefficient divides the covariance by the product of the standard deviations. This normalizes the covariance into a unit-less variable whose values are between -1 and +1.\n",
    "\n",
    "The line of best fit has a slope equal to the Pearson coefficient multiplied by SDy / SDx.\n",
    "\n",
    "<br></br>\n",
    "![png](../../img/stat_tests/stat_tests_correlation.png)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "___\n",
    "\n",
    "# MODELING\n",
    "## Overview\n",
    "\n",
    "Linear Regression:\n",
    "+ only incude variables that are correlated to the outcome.\n",
    "+ check for collinearity.\n",
    "\n",
    "<br></br>\n",
    "![png](../../img/stat_tests/stat_tests_modeling.png)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## TODO - Topics\n",
    "\n",
    "+ linear regression & link with t-test\n",
    "+ ANOVA\n",
    "+ Chi-square\n",
    "+ F-statistic\n",
    "\n",
    "https://www.annualreviews.org/doi/pdf/10.1146/annurev.publhealth.23.100901.140546\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "___\n",
    "\n",
    "# TESTING FOR NORMALITY\n",
    "## Parametric Assumptions of Normality\n",
    "\n",
    "T-tests and ANOVA assume that all the samples are normally distributed. Testing for normality is required for small samples but not for large ones, as the mean of large samples is close to the population mean. Testing for normality can be done with the Shapiro-Wilk test (or visually with QQ-plots).\n",
    "\n",
    "Non-parametric tests can be used when\n",
    "+ the assumption of normality is not met. \n",
    "+ the **mean** is **not the most appropriate** parameter to describe the population.\n",
    "\n",
    "They are less sensitive than parametric tests, which means their chances of true positives is lower and chances of false negatives are higher.\n",
    "\n",
    "_Note: many statistical methods assume the data is roughly normal. This assumption must always be checked first: many things that you might assume are normally distributed are actually not. In particular, outliers are extremely unlikely for normally distributed data; if your data does have extreme values, the normal distribution might not be the best description._\n",
    "\n",
    "_Note: We can compare the ECDF to the theoritical CDF of the normal distribution with same mean and standard deviation to assess if the data is normally distributed._\n",
    "\n",
    "References:\n",
    "+ discussions around the importance of normality assumptions can be found [here](https://www.annualreviews.org/doi/pdf/10.1146/annurev.publhealth.23.100901.140546) and [here](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6676026/).\n",
    "+ discussions around t-tests vs non-parametric tests can be found [here](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3445820/#B5) and [here](https://www.contemporaryclinicaltrials.com/article/S1551-7144(09)00109-8/fulltext).\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Q-Q Plots\n",
    "\n",
    "### Construction\n",
    "\n",
    "Q–Q (quantile-quantile) plots compare two probability distributions by plotting their quantiles against each other. They are commonly used to compare a dataset to a theoretical model, providing a graphical assessment of \"goodness of fit\" rather than a numerical summary.\n",
    "\n",
    "_Note: When the two datasets have the same size, the Q_Q plot orders each set in increasing order and pairs off the corresponding values. Otherwise, it is necessary to interpolate quantile estimates for the smallest dataset._\n",
    "\n",
    "_Note: in an ordered sample, the kth-smallest value is called its [kth-order statistic](https://en.wikipedia.org/wiki/Order_statistic). For the normal distribution, tje order statistics are called [rankits](https://en.wikipedia.org/wiki/Rankit)._\n",
    "\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "If the two distributions being compared are similar, the points in the Q–Q plot will approximately lie on the line y = x. If the distributions are linearly related, the points in the Q–Q plot will approximately lie on a line, but not necessarily on the line y = x.\n",
    "\n",
    "A non-linear pattern suggests the two datasets don't have the same probability distribution.\n",
    "\n",
    "\n",
    "### Examples\n",
    "\n",
    "The examples below show PDFs, CDFs and QQ-plots for a few common distributions. Note that the PDF of actual samples can only be approximated by histograms and Kernel Density Estimates, so the CDF will be easier to analyze.\n",
    "\n",
    "![qqplot](../../img/qq-plot.png)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Shapiro-Wilk Test\n",
    "\n",
    "The Shapiro–Wilk test tests the null hypothesis that a sample $X_1, ..., X_n$ came from a normally distributed population. We reject the null hypothesis if the p-value is below $\\alpha$, typically 0.05.\n",
    "\n",
    " Below is the test performed on three species of iris: all the test statistics are above $\\alpha$ so we fail to reject the null hypothesis.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "p-value for setosa: 0.055\np-value for versicolor: 0.158\np-value for virginica: 0.110\n"
     ]
    }
   ],
   "source": [
    "# load & format iris dataset\n",
    "iris = datasets.load_iris()\n",
    "iris_df = pd.DataFrame(iris.data, columns = iris.feature_names)\n",
    "iris_df['species'] = [iris.target_names[i] for i in iris.target]\n",
    "\n",
    "# sample statistics for iris species\n",
    "for species in ['setosa', 'versicolor', 'virginica']:\n",
    "\n",
    "    petal_length = iris_df.loc[iris_df['species'] == species, 'petal length (cm)'].to_numpy()\n",
    "    _, sample_p = stats.shapiro(petal_length)\n",
    "    print('p-value for {:}: {:.3f}'.format(species, sample_p))\n"
   ]
  },
  {
   "source": [
    "## Jarque-Bera Test\n",
    "\n",
    "The Jarque–Bera test is a goodness-of-fit test based on the sample skewness and kurtosis: its null hypothesis states that both skewness and excess kurtosis are zero. If the data comes from a normal distribution, the JB test statistic asymptotically follows a chi-squared distribution with two degrees of freedom.\n",
    "\n",
    "The chi-squared approximation is overly sensitive for small samples, often rejecting the null hypothesis when it is true (large Type I error rate). This is why this test is only recommended for large samples (n > 2000).\n",
    "\n",
    "_Note: some implementations interpolate p-values for small samples via Monte-Carlo simulations, in order to account for discrepancies between calculations and true alpha values._\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}